{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `pandas` Part 7: Combining Datasets with `concat()`\n",
    "\n",
    "# Learning Objectives\n",
    "## By the end of this tutorial you will be able to:\n",
    "1. Combine DataFrames and/or Series with `concat()`\n",
    "2. Understand a multi-index\n",
    "3. Reset an index with `reset_index()`\n",
    "4. Perform descriptive analytics on a combined DataFrame\n",
    "\n",
    "## Files Needed for this lesson:\n",
    ">- `CAvideos.csv`\n",
    ">- `GBvideos.csv`\n",
    ">- Download this csv files from Canvas prior to the lesson\n",
    ">- C:\\\\Users\\\\mimc2537\\\\OneDrive - UCB-O365\\\\python\\\\pandas\\\\\n",
    "\n",
    "## The general steps to working with pandas:\n",
    "1. import pandas as pd\n",
    "2. Create or load data into a pandas DataFrame or Series\n",
    "3. Reading data with `pd.read_`\n",
    ">- Excel files: `pd.read_excel('fileName.xlsx')`\n",
    ">- Csv files: `pd.read_csv('fileName.csv')`\n",
    ">- Note: if the file you want to read into your notebook is not in the same folder you can do one of two things:\n",
    ">>- Move the file you want to read into the same folder/directory as the notebook\n",
    ">>- Type out the full path into the read function\n",
    "4. After steps 1-3 you will want to check out your DataFrame\n",
    ">- Use `shape` to see how many records and columns are in your DataFrame\n",
    ">- Use `head()` to show the first 5-10 records in your DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction Notes on Combining Data Using `pandas`\n",
    "1. Being able to combine data from multiple sources is a critical skill for analytics professionals\n",
    "2. We will learn the `pandas` way of combining data but there are similarities here to SQL\n",
    "3. Why combine data with `pandas` if you can do the same thing in SQL?\n",
    ">- The answer to this depends on the project\n",
    ">- Some projects may be completed more efficiently all with `pandas` so you wouldn't necessarily need SQL\n",
    ">- For some projects incorporating SQL into our python code makes sense\n",
    ">- In a an analytics job, you will likely use both python and SQL to get the job done! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial set-up steps\n",
    "1. import modules and check working directory\n",
    "2. Read data in\n",
    "3. Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Read Data Into a DataFrame with `read_csv()`\n",
    ">- file names: \n",
    ">>- `CAvideos.csv`\n",
    ">>- `GBvideos.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how many rows and columns are in our DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check a couple of rows of data in one of the new DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining DataFrames\n",
    ">- The three common ways to combine datastest in pandas is with `concat()`, `join()`, and `merge()`\n",
    ">- `concat()` will take two DataFrames or Series and append them together\n",
    ">>- This is basically taking DataFrames and stacking their data on top of each other into one DataFrame\n",
    ">>- For `concat()` you need the columns/fields in both DataFrames to the be the same\n",
    ">- `join()` \"links\" DataFrames together based on a common field/column between the two\n",
    ">- `merge()` also links DataFrames together based on common field/columns but with different syntax.\n",
    ">>- We will cover the most basic join in this class\n",
    ">>- A more in depth study of joins is provided in SQL focused courses\n",
    ">>- Pandas join reference for further study: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the YouTube DataFrames to practice combining data with pandas\n",
    ">- The YouTube datasets store data on various YouTube trending statistics\n",
    ">- Our example datasets show several months of data and daily trending YouTube videos.\n",
    "\n",
    ">- For more information and for other YouTube datasets see the following link:\n",
    ">>- https://www.kaggle.com/datasnaek/youtube-new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, creating a new DataFrame that appends the Canadian and British YouTube DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some notes on the previous code\n",
    ">- Line 1: We define a new DataFrame named `CanUK` which is defined as the concatenation,`concat()`, of two datasets\n",
    ">>- Dataset 1 = canadian_youtube\n",
    ">>- Dataset 2 = uk_youtube\n",
    ">>- The `concat()` function takes the two (or more if applicable) DataFrames and \"stacks\" them on top of each\n",
    ">- Line 2: We use `keys` option to define a multi-index (aka hierarchical index)\n",
    ">>- Because our datasets represent YouTube videos from different countries we pass the abbreviated names of those countries as a list to `keys`\n",
    ">>- Enter the keys names in order they appear in line 1 (e.g., 'can' first, 'uk' second)\n",
    ">- Line 3: We use the `names` option to label our index columns from line 2\n",
    ">>- Without the `names` option we would not have anything above our index columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the index for any dataframe using `DataFrame.index`\n",
    ">- Note how `concat()` uses the rowid's for each country's dataset versus continuing the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at our new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Did using `concat()` work to append the two DataFrames together? \n",
    ">- Check the shape of your new DataFrame\n",
    ">- Compare the number of records to each one individually\n",
    ">>- canadian_youtube = 40881 records\n",
    ">>- uk_youtube = 38916 records\n",
    ">>- 40881 + 38916 = 79797 total records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `reset_index`:\n",
    "##### Note: You can reset a an index with `reset_index` \n",
    ">- This can be useful for some situations\n",
    ">- For a multi-index you can pass the `level` option and specify what index you want to reset\n",
    ">- Note: To make the change to our current DataFrame we would need to use the option, `inplace=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now some descriptive analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What channels have the most trending videos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the quantitative descriptive statistics for TheEllenShow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alternatively, you can use `loc[]` to peform the filtering operation\n",
    ">- The use of `where()` or `loc[]` depends on the question/purpose or sometimes just personal preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What were the total YouTube videos, total views, likes and dislikes for TheEllenShow?\n",
    ">- Using the agg() function to calculate specific aggregations on different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the totals for TheEllenShow's top 5 most viewed videos?\n",
    ">- Only include the title names as part of the output (not channel or any other categorical fields)\n",
    ">- Include total views, likes, dislikes, and comment count in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Notes on the Previous Example\n",
    ">- Our pandas code in the previous example is similar to SQL in the following ways\n",
    "    1. `loc[CanUk.channel_title == 'TheEllenShow',` is SQL equivalent to `WHERE channel_title = 'TheEllenShow'`\n",
    "    2. `['title','views','likes','dislikes','comment_count']` is SQL equivalent to:\n",
    "        `SELECT title, sum(views),sum(likes),sum(dislikes),sum(comment_count)`\n",
    "    3. `groupby(['title`]) is SQL equivalent to GROUP BY title\n",
    "    4. Now in pandas we enter the aggregation after the `groupby()`, in this example `sum()`\n",
    "      >>- In SQL we write the aggregation in the SELECT statement\n",
    "      \n",
    "## In future lessons we will continue to learn how pandas and SQL relate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
